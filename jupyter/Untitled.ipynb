{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\gdrive\\Projects\\Porto_Seguro\\stacking\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = utils.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"ps_car_13\", \"ps_reg_03\", \"ps_ind_05_cat\", \"ps_ind_03\", \"ps_ind_15\", \"ps_reg_02\", \"ps_car_14\", \"ps_car_12\", \"ps_car_01_cat\", \n",
    "\"ps_car_07_cat\",\"ps_ind_17_bin\", \"ps_car_03_cat\", \"ps_reg_01\", \"ps_car_15\", \"ps_ind_01\", \"ps_ind_16_bin\", \"ps_ind_07_bin\", \"ps_car_06_cat\", \n",
    "\"ps_car_04_cat\", \"ps_ind_06_bin\", \"ps_car_09_cat\", \"ps_car_02_cat\", \"ps_ind_02_cat\", \"ps_car_11\", \"ps_car_05_cat\", \"ps_calc_09\", \"ps_calc_05\", \n",
    "\"ps_ind_08_bin\", \"ps_car_08_cat\", \"ps_ind_09_bin\", \"ps_ind_04_cat\", \"ps_ind_18_bin\", \"ps_ind_12_bin\", \"ps_ind_14\"]\n",
    "combs = [('ps_reg_01', 'ps_car_02_cat'),  ('ps_reg_01', 'ps_car_04_cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488028, 57)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8f28ca73cacf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbojan_engineer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\gdrive\\Projects\\Porto_Seguro\\stacking\\utils\\utils.py\u001b[0m in \u001b[0;36mbojan_engineer\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mlbl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mlbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name1' is not defined"
     ]
    }
   ],
   "source": [
    "combined = utils.bojan_engineer(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f1, f2 in combs:\n",
    "        name = f1 + \"_plus_\" + f2\n",
    "        df[name1] = df[f1].apply(lambda x: str(x)) + \"_\" + df[f2].apply(lambda x: str(x))\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(df[name].values))\n",
    "        df[name1] = lbl.transform(list(df[name1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0\n",
      "Fold  0\n",
      "\n",
      "Fold  1\n",
      "\n",
      "Fold  2\n",
      "\n",
      "Fold  3\n",
      "\n",
      "Fold  4\n"
     ]
    }
   ],
   "source": [
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "\n",
    "def target_encode(trn_series=None,    # Revised to encode validation series\n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)\n",
    "    \n",
    "# Read data\n",
    "train_df = pd.read_csv('data/train.csv', na_values=\"-1\") # .iloc[0:200,:]\n",
    "test_df = pd.read_csv('data/test.csv', na_values=\"-1\")\n",
    "\n",
    "# from olivier\n",
    "train_features = [\"ps_car_13\", \"ps_reg_03\", \"ps_ind_05_cat\", \"ps_ind_03\", \"ps_ind_15\", \"ps_reg_02\", \"ps_car_14\", \"ps_car_12\", \"ps_car_01_cat\", \"ps_car_07_cat\",\"ps_ind_17_bin\", \"ps_car_03_cat\", \"ps_reg_01\", \"ps_car_15\", \"ps_ind_01\", \"ps_ind_16_bin\", \"ps_ind_07_bin\", \"ps_car_06_cat\", \"ps_car_04_cat\", \"ps_ind_06_bin\", \"ps_car_09_cat\", \"ps_car_02_cat\", \"ps_ind_02_cat\", \"ps_car_11\", \"ps_car_05_cat\", \"ps_calc_09\", \"ps_calc_05\",  \"ps_ind_08_bin\", \"ps_car_08_cat\", \"ps_ind_09_bin\", \"ps_ind_04_cat\", \"ps_ind_18_bin\", \"ps_ind_12_bin\", \"ps_ind_14\"]\n",
    "# add combinations\n",
    "combs = [('ps_reg_01', 'ps_car_02_cat'),  ('ps_reg_01', 'ps_car_04_cat')]\n",
    "\n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    \n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "    \n",
    "\n",
    "\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]\n",
    "\n",
    "# Set up folds\n",
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n",
    "np.random.seed(0)\n",
    "    \n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    # Enocode data\n",
    "    for f in f_cats:\n",
    "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "                                                        trn_series=X_train[f],\n",
    "                                                        val_series=X_valid[f],\n",
    "                                                        tst_series=X_test[f],\n",
    "                                                        target=y_train,\n",
    "                                                        min_samples_leaf=200,\n",
    "                                                        smoothing=10,\n",
    "                                                        noise_level=0\n",
    "                                                        )\n",
    "    # Run model for this fold\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "    X_valid = X_valid.fillna(X_valid.mean())\n",
    "    X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ps_car_09_cat_avg.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ps_reg_01_plus_ps_car_04_cat_avg.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ps_reg_01.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ps_car_04_cat.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('data/train.csv', na_values=\"-1\") # .iloc[0:200,:]\n",
    "test = pd.read_csv('data/test.csv', na_values=\"-1\")\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['ps_car_04_cat' + \"_avg\"], X_val['ps_car_04_cat' + \"_avg\"], X_test['ps_car_04_cat' + \"_avg\"] = target_encode(\n",
    "                                                trn_series=X_train['ps_car_04_cat'],\n",
    "                                                val_series=X_val['ps_car_04_cat'],\n",
    "                                                tst_series=X_test['ps_car_04_cat'],\n",
    "                                                target=y_train,\n",
    "                                                min_samples_leaf=200,\n",
    "                                                smoothing=10,\n",
    "                                                noise_level=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "\n",
      "Fold  1\n",
      "\n",
      "Fold  2\n",
      "\n",
      "Fold  3\n",
      "\n",
      "Fold  4\n"
     ]
    }
   ],
   "source": [
    "def bojan_engineer(df):\n",
    "\t# from olivier\n",
    "\tfeatures = [\"ps_car_13\", \"ps_reg_03\", \"ps_ind_05_cat\", \"ps_ind_03\", \"ps_ind_15\", \"ps_reg_02\", \"ps_car_14\", \"ps_car_12\", \"ps_car_01_cat\", \n",
    "\t\"ps_car_07_cat\",\"ps_ind_17_bin\", \"ps_car_03_cat\", \"ps_reg_01\", \"ps_car_15\", \"ps_ind_01\", \"ps_ind_16_bin\", \"ps_ind_07_bin\", \"ps_car_06_cat\", \n",
    "\t\"ps_car_04_cat\", \"ps_ind_06_bin\", \"ps_car_09_cat\", \"ps_car_02_cat\", \"ps_ind_02_cat\", \"ps_car_11\", \"ps_car_05_cat\", \"ps_calc_09\", \"ps_calc_05\", \n",
    "\t\"ps_ind_08_bin\", \"ps_car_08_cat\", \"ps_ind_09_bin\", \"ps_ind_04_cat\", \"ps_ind_18_bin\", \"ps_ind_12_bin\", \"ps_ind_14\"]\n",
    "\n",
    "\t# add combinations\n",
    "\tcombs = [('ps_reg_01', 'ps_car_02_cat'),  ('ps_reg_01', 'ps_car_04_cat')]\n",
    "\n",
    "\tdf = df[features]\n",
    "\n",
    "\tfor f1, f2 in combs:\n",
    "\t    name = f1 + \"_plus_\" + f2\n",
    "\t    \n",
    "\t    df[name] = df[f1].apply(lambda x: str(x)) + \"_\" + df[f2].apply(lambda x: str(x))\n",
    "\t    # Label Encode\n",
    "\t    df = pd.get_dummies(df, columns=[name])\n",
    "\n",
    "\treturn df\n",
    "\n",
    "def fold_smoothing_encode(X_train, X_val, X_test):\n",
    "    for f in X_train.columns[X_train.columns.str.endswith('cat')==True]:\n",
    "        X_train[f + \"_avg\"], X_val[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "                                                        trn_series=X_train[f],\n",
    "                                                        val_series=X_val[f],\n",
    "                                                        tst_series=X_test[f],\n",
    "                                                        target=y_train,\n",
    "                                                        min_samples_leaf=200,\n",
    "                                                        smoothing=10,\n",
    "                                                        noise_level=0\n",
    "                                                        )\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "\n",
    "train = bojan_engineer(train)\n",
    "test = bojan_engineer(test)\n",
    "\n",
    "# Set up folds\n",
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n",
    "np.random.seed(0)\n",
    "    \n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    \n",
    "    # Create data for this fold\n",
    "    y_train, y_val = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_val = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    X_train, X_val, X_test = fold_smoothing_encode(X_train, X_val, X_test)\n",
    "\n",
    "    # Run model for this fold\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "    X_val = X_val.fillna(X_val.mean())\n",
    "    X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476170, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
